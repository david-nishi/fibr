{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create color-FA gifs and static images for use in citizen science app fibr.dev\n",
    "\n",
    "This notebook creates gifs and static images of color-FA plotted on top of B0 images for use in the citizen science QC app [fibr.dev](https://fibr.dev)\n",
    "\n",
    "It uses the cloudknot library to distribute the computational load on AWS Batch, but the functions defined in this notebook can also be run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richford/miniconda3/envs/cloudknot-pyafq/lib/python3.8/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/richford/miniconda3/envs/cloudknot-pyafq/lib/python3.8/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import cloudknot as ck  # for distributing the workload on AWS Batch\n",
    "import AFQ.data as afqd  # for downloading specific subjects from BIDS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richford/miniconda3/envs/cloudknot-pyafq/lib/python3.8/site-packages/bids/layout/models.py:98: FutureWarning: The 'extension' entity currently excludes the leading dot ('.'). As of version 0.14.0, it will include the leading dot. To suppress this warning and include the leading dot, use `bids.config.set_option('extension_initial_dot', True)`.\n",
      "  warnings.warn(\"The 'extension' entity currently excludes the leading dot ('.'). \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving subject S3 keys\n",
      "[########################################] | 100% Completed |  0.6s\n"
     ]
    }
   ],
   "source": [
    "# This is the pyAFQ data class that stores information about a BIDS study on AWS S3\n",
    "\n",
    "study = afqd.S3BIDSStudy(\n",
    "    study_id=\"hbn-qsiprep\",  # Name it anything you want\n",
    "    bucket=\"fcp-indi\",  # AWS S3 Bucket\n",
    "    s3_prefix=\"data/Projects/HBN/BIDS_curated/derivatives/qsiprep\",  # The AWS S3 key for this study\n",
    "    anon=True,  # Anon=True for public buckets, otherwise you will have to have credentials\n",
    "    subjects=[1],  # Grab the S3 keys for only the first subject\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1653\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of subjects\n",
    "subjects = study._all_subjects\n",
    "print(len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate_gifs.\n",
    "# This will create all the animated gifs and static png files for one subject\n",
    "# And then store them in AWS S3\n",
    "# The input and output S3 locations are hard-coded inside the function\n",
    "# One of the ideosyncracies of cloudknot is that all necessary imports must be done inside the function.\n",
    "\n",
    "def create_gifs(subject):\n",
    "    import AFQ.data as afqd\n",
    "    import AFQ.registration as reg\n",
    "    import bids\n",
    "    import dipy.reconst.dti as dti\n",
    "    import imageio\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import os.path as op\n",
    "\n",
    "    from dipy.io.image import load_nifti, save_nifti\n",
    "    from dipy.io import read_bvals_bvecs\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    from pygifsicle import optimize\n",
    "    from s3fs import S3FileSystem\n",
    "    from scipy import ndimage\n",
    "    from scipy.special import expit\n",
    "    \n",
    "    # Instantiate a study object, grabbing only the S3 keys for the input subject\n",
    "    study = afqd.S3BIDSStudy(\n",
    "        study_id=\"hbn-qsiprep\",\n",
    "        bucket=\"fcp-indi\",\n",
    "        s3_prefix=\"data/Projects/HBN/BIDS_curated/derivatives/qsiprep\",\n",
    "        anon=True,\n",
    "        subjects=[subject]\n",
    "    )\n",
    "    \n",
    "    # Download that particular subject to a local folder\n",
    "    local_bids_folder = \"hbn\"\n",
    "    output_bucket = \"fibr-gifs\"\n",
    "    study.download(local_bids_folder)\n",
    "    layout = bids.BIDSLayout(local_bids_folder, validate=False)\n",
    "\n",
    "    # Specify the slices that we would like to save as a fraction of total number of slices\n",
    "    scale_fa = True\n",
    "    slice_ratios = np.linspace(0.4, 0.6, 4, endpoint=True)\n",
    "    slice_ratios[0] = 0.42\n",
    "    slice_ratios[-1] = 0.58\n",
    "    \n",
    "    # Specify that slice range for the animated gifs\n",
    "    slice_gif_offsets = np.arange(-5, 6)\n",
    "    \n",
    "    # Calculate the frames-per-second for the animated gifs\n",
    "    fps = len(slice_gif_offsets) / 2.0\n",
    "    \n",
    "    # Specify the image dimensions, note that SwipesForScience images should be square\n",
    "    img_height = 4.8\n",
    "    aspect_ratio = 1.0\n",
    "    img_width = aspect_ratio * img_height\n",
    "    figsize = (img_width, img_height)\n",
    "\n",
    "    # Specify local filenames\n",
    "    subject = subject.replace(\"sub-\", \"\")    \n",
    "    fname_pdf = f\"sub-{subject}_desc-b0colorfa_slice-\"\n",
    "    fname_gif = f\"sub-{subject}_desc-b0colorfa_slice-\"\n",
    "    fname_fa = f\"sub-{subject}_tensor_fa.nii.gz\"\n",
    "    fname_rgb = f\"sub-{subject}_tensor_rgb.nii.gz\"\n",
    "    \n",
    "    # Use pybids to grab the necessary image files\n",
    "    bids_filters = {\"subject\": subject, \"return_type\": \"filename\"}\n",
    "    \n",
    "    fb0 = layout.get(suffix=\"dwiref\", extension=\"nii.gz\", **bids_filters)[0]\n",
    "    fdwi = layout.get(extension=\"nii.gz\", suffix=\"dwi\", **bids_filters)[0]\n",
    "    fmask = layout.get(suffix=\"mask\", datatype=\"dwi\", extension=\"nii.gz\", **bids_filters)[0]\n",
    "    ft1w = layout.get(suffix=\"T1w\", extension=\"nii.gz\", space=None, **bids_filters)[0]\n",
    "    fwm = layout.get(suffix=\"probseg\", space=None, extension=\"nii.gz\", **bids_filters)\n",
    "    fwm = [fn for fn in fwm if \"label-WM\" in fn][0]\n",
    "    \n",
    "    # Load the niftis\n",
    "    b0_data, b0_affine = load_nifti(fb0)\n",
    "    t1w_data, t1w_affine = load_nifti(ft1w)\n",
    "    mask_data, mask_affine = load_nifti(fmask)\n",
    "    data, affine = load_nifti(fdwi)\n",
    "    wm_data, wm_affine = load_nifti(fwm)\n",
    "    \n",
    "    # Resample to dwi resolution\n",
    "    t1w_dwi = reg.resample(t1w_data, data[:, :, :, 0], t1w_affine, affine)\n",
    "    wm_dwi = reg.resample(wm_data, data[:, :, :, 0], wm_affine, affine)\n",
    "    mask_dwi = reg.resample(mask_data, data[:, :, :, 0], mask_affine, affine)\n",
    "    b0_dwi = reg.resample(b0_data, data[:, :, :, 0], b0_affine, affine)\n",
    "    \n",
    "    # Load the gradient table\n",
    "    fbval = layout.get_bval(path=fdwi, subject=subject)\n",
    "    fbvec = layout.get_bvec(path=fdwi, subject=subject)\n",
    "    bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "    gtab = gradient_table(bvals, bvecs)\n",
    "\n",
    "    # Fit a tensor model and compute FA\n",
    "    tenmodel = dti.TensorModel(gtab)\n",
    "    tenfit = tenmodel.fit(data)\n",
    "    FA = dti.fractional_anisotropy(tenfit.evals)\n",
    "    FA = np.clip(FA, 0, 1)\n",
    "\n",
    "    # Convert to colorFA image as in DIPY documentation\n",
    "    FA_masked = FA * wm_dwi\n",
    "    RGB = dti.color_fa(FA_masked, tenfit.evecs)\n",
    "\n",
    "    RGB = np.array(255 * RGB, 'uint8')\n",
    "    save_nifti(fname_fa, FA_masked.astype(np.float32), affine)\n",
    "    save_nifti(fname_rgb, RGB, affine)    \n",
    "    \n",
    "    def trim_zeros(arr, margin=0, trim_dims=None):\n",
    "        '''\n",
    "        Trim the leading and trailing zeros from a N-D array.\n",
    "\n",
    "        :param arr: numpy array\n",
    "        :param margin: how many zeros to leave as a margin\n",
    "        :returns: trimmed array\n",
    "        :returns: slice object\n",
    "        '''\n",
    "        s = []\n",
    "        if trim_dims is None:\n",
    "            trim_dims = list(range(arr.ndim))\n",
    "\n",
    "        for dim in range(arr.ndim):\n",
    "            start = 0\n",
    "            end = -1\n",
    "\n",
    "            if dim in trim_dims:\n",
    "                slice_ = [slice(None)]*arr.ndim\n",
    "\n",
    "                go = True\n",
    "                while go:\n",
    "                    slice_[dim] = start\n",
    "                    go = not np.any(arr[tuple(slice_)])\n",
    "                    start += 1\n",
    "                start = max(start-1-margin, 0)\n",
    "\n",
    "                go = True\n",
    "                while go:\n",
    "                    slice_[dim] = end\n",
    "                    go = not np.any(arr[tuple(slice_)])\n",
    "                    end -= 1\n",
    "                end = arr.shape[dim] + min(-1, end+1+margin) + 1\n",
    "\n",
    "                s.append(slice(start,end))\n",
    "            else:\n",
    "                s.append(slice(None, None, None))\n",
    "        return arr[tuple(s)], tuple(s)\n",
    "        \n",
    "    def pad_square_2d(arr):\n",
    "        \"\"\"Pad a slice so that it is square\"\"\"\n",
    "        dim_x, dim_y = arr.shape[0], arr.shape[1]\n",
    "        dim_max = max(dim_x, dim_y)\n",
    "        pad_xr = (dim_max - dim_x) // 2\n",
    "        pad_xl = dim_max - dim_x - pad_xr\n",
    "        pad_yr = (dim_max - dim_y) // 2\n",
    "        pad_yl = dim_max - dim_y - pad_yr\n",
    "\n",
    "        pad_width = [(pad_xl, pad_xr), (pad_yl, pad_yr)]\n",
    "        for i in range(arr.ndim - 2):\n",
    "            pad_width.append((0, 0))\n",
    "        return np.pad(arr, pad_width=pad_width)\n",
    "\n",
    "    # Compute the indices of the slices\n",
    "    slice_indices = np.array(slice_ratios * b0_dwi.shape[-1], dtype=\"uint8\")\n",
    "\n",
    "    # Trim zeros off of everything\n",
    "    mask_trim, trim_slices = trim_zeros(mask_dwi, margin=5, trim_dims=(0, 1))\n",
    "    t1w_dwi = t1w_dwi[trim_slices]\n",
    "    b0_dwi = b0_dwi[trim_slices]\n",
    "    RGB = RGB[trim_slices + (slice(None, None, None),)]\n",
    "    FA_masked = FA_masked[trim_slices]\n",
    "    \n",
    "    # Square everything\n",
    "    t1w_dwi = pad_square_2d(t1w_dwi)\n",
    "    RGB = pad_square_2d(RGB)\n",
    "    FA_masked = pad_square_2d(FA_masked)\n",
    "    b0_dwi = pad_square_2d(b0_dwi)\n",
    "\n",
    "    # Create the local output dir\n",
    "    png_dir = f\"sub-{subject}_gifs\"\n",
    "    os.makedirs(png_dir, exist_ok=True)\n",
    "    \n",
    "    gif_fnames = []\n",
    "    # First loop is over different image sizes. You can decide which ones to use\n",
    "    # later when you make your SwipesForScience manifest file\n",
    "    for figsize_multiplier, figsize_string in zip([1.5, 2.0], [\"_medium\", \"_large\"]):\n",
    "        my_figsize = tuple(x * figsize_multiplier for x in figsize)\n",
    "        \n",
    "        # Second loop if for individual slices in the gif image\n",
    "        for gif_idx, base_slice_idx in enumerate(slice_indices):\n",
    "            images = []\n",
    "            for offset_idx, slice_offset in enumerate(slice_gif_offsets):\n",
    "                slice_idx = base_slice_idx + slice_offset\n",
    "\n",
    "                fig, ax = plt.subplots(1, 1, figsize=my_figsize)\n",
    "\n",
    "                slice_anat = ndimage.rotate(b0_dwi[:, :, slice_idx], -90)\n",
    "                slice_rgb = ndimage.rotate(RGB[:, :, slice_idx], -90)\n",
    "\n",
    "                fa_slice = FA_masked[:, :, slice_idx]\n",
    "                if scale_fa:\n",
    "                    xmax = 5\n",
    "                    trans_x = -xmax + 2 * xmax * (fa_slice + 0.1)\n",
    "                    fa_slice = expit(trans_x)\n",
    "\n",
    "                alpha = ndimage.rotate(np.array(255 * fa_slice, \"uint8\"), -90)[:, :, np.newaxis]\n",
    "                slice_rgba = np.concatenate([slice_rgb, alpha], axis=-1)\n",
    "\n",
    "                _ = ax.imshow(slice_anat, cmap=plt.cm.Greys_r)\n",
    "                _ = ax.imshow(slice_rgba)\n",
    "                _ = ax.axis(\"off\")\n",
    "                \n",
    "                file_path = op.join(\n",
    "                    png_dir,\n",
    "                    fname_gif + str(gif_idx) + figsize_string + \"_\" + str(offset_idx) + \".png\"\n",
    "                )\n",
    "                if slice_offset == 0:\n",
    "                    gif_fnames.append(op.abspath(file_path))\n",
    "                \n",
    "                fig.savefig(file_path, bbox_inches=\"tight\")\n",
    "                plt.close(fig)\n",
    "\n",
    "                images.append(imageio.imread(file_path))\n",
    "\n",
    "            images = images + images[-2:0:-1]\n",
    "\n",
    "            file_path = op.join(\n",
    "                png_dir,\n",
    "                fname_gif + str(gif_idx) + figsize_string + \".gif\"\n",
    "            )\n",
    "            \n",
    "            # Save and optimize the gif\n",
    "            imageio.mimsave(file_path, images, loop=0, fps=fps, subrectangles=True)\n",
    "            optimize(file_path)\n",
    "            \n",
    "            gif_fnames.append(op.abspath(file_path))\n",
    "            \n",
    "    fs = S3FileSystem()\n",
    "    \n",
    "    # Save output to S3\n",
    "    for fn in gif_fnames:\n",
    "        fs.put(fn, \"/\".join([output_bucket, op.basename(fn)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this notebook is all cloudknot stuff to parallelize this function that we just wrote over all of the subjects using AWS Batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = ck.DockerImage(\n",
    "#     name=\"fibr-gifs\",\n",
    "    func=create_gifs,\n",
    "    base_image=\"pygifsicle:latest\",\n",
    "    github_installs=\"https://github.com/yeatmanlab/pyAFQ.git@master\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.build(tags=[\"fibr-gifs-20201116\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = ck.aws.DockerRepo(name=ck.get_ecr_repo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The very first time you run this, this command could take a while to build and push the docker image\n",
    "di.push(repo=repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify bid_percentage to use Spot instances\n",
    "\n",
    "knot = ck.Knot(\n",
    "    name=f\"fibr-gifs-20201123-0\",\n",
    "    docker_image=di,\n",
    "    pars_policies=(\"AmazonS3FullAccess\",),\n",
    "    bid_percentage=100,\n",
    "    memory=16000,\n",
    "    job_def_vcpus=4,\n",
    "    max_vcpus=4096,\n",
    "    retries=3,\n",
    "    volume_size=65,\n",
    "    aws_resource_tags={\"Project\": \"HBN-FCP-INDI\"},\n",
    ")\n",
    "\n",
    "# Or retrieve the above knot from config file if you've already used it before\n",
    "# knot = ck.Knot(name=f\"fibr-gifs-20201116-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I usually like to start by running on a small subset of the data just to make sure \n",
    "# everything is working before I do the production run.\n",
    "results = knot.map(subjects[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those ten subject ran successfully, so now let's do the rest\n",
    "results = knot.map(subjects[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the subjects failed the first time through. So I went in by hand to find the indices of these failed runs and then made a second pass to finish all of the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-NDARZE389XF0',\n",
       " 'sub-NDARJV377HG4',\n",
       " 'sub-NDARVT454LAE',\n",
       " 'sub-NDARKZ519FBT',\n",
       " 'sub-NDARJY747PRJ',\n",
       " 'sub-NDARHT844LZR',\n",
       " 'sub-NDARRB403PDE',\n",
       " 'sub-NDARLE554GYT',\n",
       " 'sub-NDARJE686DJL',\n",
       " 'sub-NDAREB953UMY',\n",
       " 'sub-NDARAJ689BVN',\n",
       " 'sub-NDARZY101JNB',\n",
       " 'sub-NDARHY676RYH',\n",
       " 'sub-NDARRR622MYT',\n",
       " 'sub-NDARNP423EJQ',\n",
       " 'sub-NDARPF682GDC',\n",
       " 'sub-NDARAH304ED7',\n",
       " 'sub-NDARHR099EWX',\n",
       " 'sub-NDARZL113CU0',\n",
       " 'sub-NDARDC814WW2',\n",
       " 'sub-NDARZA982YTP',\n",
       " 'sub-NDARZL855WVA',\n",
       " 'sub-NDARCJ246FJB',\n",
       " 'sub-NDARFA089ZZG',\n",
       " 'sub-NDARTY225EWV',\n",
       " 'sub-NDARPX661BF1',\n",
       " 'sub-NDARNR459MUJ',\n",
       " 'sub-NDARWD911WBU',\n",
       " 'sub-NDARFG027BT5',\n",
       " 'sub-NDARCR743RHQ',\n",
       " 'sub-NDARRY714GEY',\n",
       " 'sub-NDARDE877RFH',\n",
       " 'sub-NDARRB338YZ0',\n",
       " 'sub-NDARRX800KW8']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_indices = [\n",
    "     25,  29,  31,  38,  40,  62,  63,  65,  72,  75,\n",
    "     89,  94,  99, 105, 106, 108, 112, 121, 128, 130,\n",
    "    135, 136, 140, 153, 167, 168, 188, 193, 195, 221,\n",
    "    222, 233, 262, 494\n",
    "]\n",
    "\n",
    "failed_subs = [subjects[10:][idx] for idx in failed_indices]\n",
    "failed_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the second batch of jobs\n",
    "results = knot.map(failed_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up all of the AWS resources we created to do this job\n",
    "knot.clobber(clobber_pars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
